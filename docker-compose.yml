services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.app
    env_file: .env
    volumes:
      - ./secrets:/run/secrets:ro
      - ./cache:/root/.cache/huggingface
      - ./models/nlp:/models/nlp:ro
    network_mode: "host"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 6
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=0,1,2,3,4,5
      - LLAMA_BACKEND=llama_cpp
      - LLAMA_MODEL_PATH=/models/nlp/llama-4-scout-17b-gguf-q4_k_m.gguf
      - ARI_URL=https://asterisk:8089/ari
    healthcheck:
      test: ["CMD", "python", "-m", "tools.healthcheck_app"]
      interval: 15s
      timeout: 3s
      retries: 10
      start_period: 20s

  tts:
    build:
      context: .
      dockerfile: Dockerfile.tts
    env_file: .env
    volumes:
      - ./cache:/root/.cache/huggingface
      - ./models/tts:/models/tts:ro
    network_mode: "host"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 2
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=6,7
      - FASTPITCH_MODEL_NAME=nvidia/tts_en_fastpitch
      - VOCODER_MODEL_NAME=nvidia/tts_hifigan
    healthcheck:
      test: ["CMD", "python", "-m", "tts_server.healthcheck"]
      interval: 15s
      timeout: 3s
      retries: 10
      start_period: 20s